"""
Demo script for Week 2 Day 7: Performance Analytics and Dashboards
Demonstrates Adariprasad's performance analytics implementation
"""

import sys
import os
from datetime import datetime
import json
import random
import numpy as np

# Add project root to path
sys.path.append(os.path.join(os.path.dirname(__file__), './'))

from src.monitoring.performance_analytics import ADPAPerformanceAnalytics

def generate_sample_execution_data(day_offset: int = 0) -> dict:
    """Generate realistic sample execution data"""
    
    base_executions = 100
    base_success_rate = 95
    
    # Add some variance based on day
    executions = base_executions + random.randint(-20, 30)
    success_rate = base_success_rate + random.uniform(-5, 3)
    
    successful = int(executions * (success_rate / 100))
    
    return {
        'total_executions': executions,
        'successful_executions': successful,
        'execution_time_seconds': random.randint(1800, 7200),  # 30min to 2hrs
        'data_volume_gb': random.uniform(50, 200),
        'cpu_utilization_avg': random.uniform(40, 85),
        'memory_utilization_avg': random.uniform(35, 80),
        'total_cost': random.uniform(25, 75),
        'data_quality_scores': [random.uniform(85, 98) for _ in range(5)],
        'model_metrics': {
            'accuracy': random.uniform(0.80, 0.95),
            'precision': random.uniform(0.75, 0.92),
            'recall': random.uniform(0.78, 0.90),
            'f1_score': random.uniform(0.76, 0.91),
            'inference_latency_ms': random.uniform(100, 500)
        },
        'errors': {
            'total': random.randint(0, 8),
            'critical': random.randint(0, 2),
            'timeout': random.randint(0, 3),
            'validation': random.randint(0, 3)
        }
    }

def main():
    print("ðŸ“Š ADPA Performance Analytics & Dashboards Demo")
    print("=" * 55)
    print("Week 2 Day 7: Performance Analytics and Dashboards")
    print("=" * 55)
    
    # Initialize performance analytics system
    print("\nðŸ”§ Initializing Performance Analytics System...")
    analytics = ADPAPerformanceAnalytics(mock_mode=True)
    print("âœ… Performance analytics system initialized successfully")
    
    # Create performance dashboard
    print("\nðŸ“ˆ Creating Performance Dashboard...")
    dashboard_result = analytics.create_performance_dashboard("ADPA-Performance-Dashboard")
    
    if dashboard_result['status'] == 'success':
        print("âœ… Performance dashboard created successfully!")
        print(f"ðŸ“Š Dashboard widgets created: {dashboard_result['widgets_created']}")
    else:
        print(f"âŒ Failed to create dashboard: {dashboard_result.get('error')}")
    
    # Generate historical performance data
    print("\nðŸ“ˆ Generating Historical Performance Data...")
    
    performance_summary = []
    
    # Simulate 7 days of performance data
    for day in range(7):
        print(f"  ðŸ“… Day {day + 1}: Tracking performance metrics...")
        
        # Generate sample execution data
        execution_data = generate_sample_execution_data(day)
        
        # Track performance metrics
        performance_metrics = analytics.track_performance_metrics(execution_data)
        
        performance_summary.append({
            'day': day + 1,
            'executions': execution_data['total_executions'],
            'success_rate': performance_metrics.get('success_rate', 0),
            'avg_time': performance_metrics.get('average_execution_time', 0),
            'throughput': performance_metrics.get('throughput_per_hour', 0),
            'cost_per_exec': performance_metrics.get('cost_per_execution', 0)
        })
    
    print(f"âœ… Generated 7 days of performance data")
    print(f"ðŸ“Š Total performance records: {len(analytics.performance_data)}")
    
    # Display performance summary
    print("\nðŸ“Š Performance Summary (Last 7 Days):")
    print("-" * 45)
    print("Day | Exec | Success% | Avg Time | Throughput | Cost/Exec")
    print("-" * 45)
    
    for summary in performance_summary:
        print(f"{summary['day']:3} | {summary['executions']:4} | "
              f"{summary['success_rate']:7.1f} | {summary['avg_time']:8.1f} | "
              f"{summary['throughput']:10.1f} | ${summary['cost_per_exec']:7.2f}")
    
    # Generate comprehensive performance report
    print("\nðŸ“‹ Generating Performance Analytics Report...")
    performance_report = analytics.generate_performance_report(days_back=7)
    
    print("âœ… Performance report generated successfully!")
    
    # Display executive summary
    print("\nðŸ† Performance Executive Summary:")
    print("-" * 35)
    
    trends = performance_report.get('performance_trends', {})
    if trends:
        for metric, data in trends.items():
            trend_icon = "ðŸ“ˆ" if data['trend'] == 'improving' else "ðŸ“‰"
            print(f"â€¢ {metric.replace('_', ' ').title()}: {data['current']:.2f} {trend_icon}")
            print(f"  Trend: {data['trend']} (avg: {data['average']:.2f})")
    
    # Display resource utilization
    print("\nðŸ”§ Resource Utilization Analysis:")
    print("-" * 30)
    
    utilization = performance_report.get('resource_utilization', {})
    if utilization:
        for resource, data in utilization.items():
            if resource == 'cpu_utilization':
                icon = "ðŸ”´" if data['average'] > 80 else "ðŸŸ¡" if data['average'] > 60 else "ðŸŸ¢"
            elif resource == 'memory_utilization':
                icon = "ðŸ”´" if data['average'] > 85 else "ðŸŸ¡" if data['average'] > 70 else "ðŸŸ¢"
            else:
                icon = "ðŸ“Š"
            
            print(f"â€¢ {icon} {resource.replace('_', ' ').title()}: {data['current']:.1f}%")
            print(f"  Average: {data['average']:.1f}% | Peak: {data['peak']:.1f}%")
    
    # Display cost analysis
    print("\nðŸ’° Cost Analysis:")
    print("-" * 15)
    
    cost_analysis = performance_report.get('cost_analysis', {})
    if cost_analysis:
        for cost_metric, data in cost_analysis.items():
            trend_icon = "ðŸ“ˆ" if data['trend'] == 'increasing' else "ðŸ“Š"
            print(f"â€¢ {cost_metric.replace('_', ' ').title()}: ${data['current']:.2f} {trend_icon}")
            print(f"  Average: ${data['average']:.2f} | Trend: {data['trend']}")
    
    # Display recommendations
    print("\nðŸ’¡ Performance Optimization Recommendations:")
    print("-" * 45)
    
    recommendations = performance_report.get('recommendations', [])
    if recommendations:
        for i, rec in enumerate(recommendations, 1):
            priority_icon = "ðŸ”´" if rec['priority'] == 'high' else "ðŸŸ¡" if rec['priority'] == 'medium' else "ðŸŸ¢"
            print(f"{i}. {priority_icon} [{rec['priority'].upper()}] {rec['category'].title()}")
            print(f"   {rec['message']}")
            
            if 'suggested_actions' in rec:
                for action in rec['suggested_actions'][:2]:  # Show first 2 actions
                    print(f"   â†’ {action}")
            print()
    else:
        print("â€¢ No specific recommendations at this time")
        print("â€¢ System is performing within optimal parameters")
    
    # Get real-time metrics
    print("\nâš¡ Real-time Performance Metrics:")
    print("-" * 30)
    
    real_time_metrics = analytics.get_real_time_metrics()
    if 'metrics' in real_time_metrics:
        metrics = real_time_metrics['metrics']
        status_icon = "ðŸŸ¢" if real_time_metrics['status'] == 'healthy' else "ðŸŸ¡"
        
        print(f"â€¢ {status_icon} System Status: {real_time_metrics['status'].upper()}")
        print(f"â€¢ Success Rate: {metrics.get('success_rate', 0):.1f}%")
        print(f"â€¢ Throughput: {metrics.get('throughput_per_hour', 0):.1f} exec/hr")
        print(f"â€¢ CPU Utilization: {metrics.get('cpu_utilization', 0):.1f}%")
        print(f"â€¢ Error Rate: {metrics.get('error_rate', 0):.2f}%")
    
    # Create capacity planning analysis
    print("\nðŸ”® Capacity Planning Analysis:")
    print("-" * 30)
    
    capacity_analysis = analytics.create_capacity_planning_analysis()
    
    if 'current_capacity' in capacity_analysis:
        current = capacity_analysis['current_capacity']
        print(f"â€¢ Current Throughput: {current.get('throughput', 0):.1f} exec/hr")
        print(f"â€¢ CPU Headroom: {current.get('cpu_headroom', 0):.1f}%")
        
        projected = capacity_analysis.get('projected_capacity', {})
        if projected:
            print("\nðŸ“ˆ 30-Day Projections:")
            for metric, value in projected.items():
                print(f"  â€¢ {metric.replace('_', ' ').title()}: {value:.1f}")
    
    # Show dashboard widget summary
    print("\nðŸ“Š Dashboard Widget Summary:")
    print("-" * 30)
    
    if dashboard_result['status'] == 'success':
        widget_types = [
            "Pipeline Execution Overview",
            "Execution Performance Metrics", 
            "Resource Utilization",
            "Cost Analytics",
            "Data Processing Performance",
            "Model Performance Analytics",
            "Error Analysis",
            "Performance Trends & Capacity Planning"
        ]
        
        for i, widget in enumerate(widget_types, 1):
            print(f"  {i}. {widget}")
    
    # Show what Week 2 Day 7 objectives were completed
    print("\nâœ… Week 2 Day 7 Objectives Completed:")
    print("-" * 40)
    print("âœ… Performance analytics dashboard creation")
    print("âœ… Advanced metrics visualization widgets")
    print("âœ… Historical performance trend analysis")
    print("âœ… Resource utilization monitoring")
    print("âœ… Cost analytics and optimization")
    print("âœ… Real-time performance metrics")
    print("âœ… Capacity planning analysis")
    print("âœ… Performance optimization recommendations")
    
    # Tutorial implementation status
    print("\nðŸ“š Tutorial Implementation Status:")
    print("-" * 35)
    print("âœ… CloudWatch dashboard creation (mocked)")
    print("âœ… Performance metrics calculation")
    print("âœ… Trend analysis algorithms")
    print("âœ… Resource utilization tracking")
    print("âœ… Cost efficiency analysis")
    print("âœ… Real-time monitoring capabilities")
    print("âœ… Capacity planning projections")
    print("âœ… Automated recommendation engine")
    
    # Save demo results
    demo_results = {
        'timestamp': datetime.now().isoformat(),
        'dashboard_widgets_created': dashboard_result.get('widgets_created', 0),
        'performance_data_points': len(analytics.performance_data),
        'recommendations_generated': len(recommendations),
        'performance_summary': performance_summary,
        'real_time_status': real_time_metrics.get('status', 'unknown')
    }
    
    # Create results directory
    os.makedirs('./data/demo_results', exist_ok=True)
    
    with open('./data/demo_results/week2_day7_performance_demo.json', 'w') as f:
        json.dump(demo_results, f, indent=2, default=str)
    
    # Next steps
    print("\nðŸš€ Next Steps (Week 2 Day 8):")
    print("-" * 35)
    print("â€¢ Anomaly detection implementation")
    print("â€¢ Advanced trend analysis")
    print("â€¢ Predictive analytics")
    print("â€¢ Machine learning-based forecasting")
    print("â€¢ Automated scaling recommendations")
    
    print(f"\nðŸ’¾ Demo results saved to: ./data/demo_results/week2_day7_performance_demo.json")
    print(f"ðŸ’¾ Performance reports saved to: {analytics.reports_dir}")
    print("\nðŸŽ‰ Week 2 Day 7 Implementation Complete!")
    
    return performance_report

if __name__ == '__main__':
    report = main()